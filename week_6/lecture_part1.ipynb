{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a292ab0-29b6-4fbc-a2bd-56a0303b0731",
   "metadata": {},
   "source": [
    "# Intermediate Text Data Analysis Techniques and Introduction to Social Media Data\n",
    "\n",
    "Table of Contents\n",
    "\n",
    "1. Social Media Data Characteristics\n",
    "2. Emoji and Emoticon Analysis\n",
    "3. Sentiment Analysis\n",
    "4. Regular Expressions for Advanced Text Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a9c578-1f04-43ec-9022-a9668c04eba3",
   "metadata": {},
   "source": [
    "## 1. Social Media Data Characteristics\n",
    "\n",
    "Social media data has some unique characteristics that make it different from other types of text data:\n",
    "\n",
    "1. Shorter texts (e.g., tweets, comments)\n",
    "2. Informal language and slang\n",
    "3. Emojis and emoticons\n",
    "4. URLs, mentions, and hashtags\n",
    "\n",
    "Understanding these characteristics is essential for effectively processing and analyzing social media data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b746f0c-5c87-48ca-bdd0-311c59c417e8",
   "metadata": {},
   "source": [
    "## 2. Emoji and Emoticon Analysis\n",
    "\n",
    "Emojis and emoticons are widely used in social media data to express emotions. Analyzing them can help us understand the sentiment of the text. We will use the emoji library to extract and analyze emojis in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5997e56-d911-4e6e-a7a8-c2b7a6579858",
   "metadata": {},
   "source": [
    "### 2.1 Extracting Emojis and Emoticons\n",
    "\n",
    "Python package: [emoji](https://carpedm20.github.io/emoji/docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab9ef5f-919c-4339-a3a7-f68142563c90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788fac9f-4b1f-4ee5-912b-c0939b3e682d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import emoji\n",
    "\n",
    "print(emoji.emojize('Python is :thumbs_up:'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ab99f5-931f-470b-98bb-a2fd85148443",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(emoji.emojize(\"Python is fun :red_heart:\", variant=\"text_type\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c563eaf-e005-411f-924c-be9244e0aae1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(emoji.emojize(\"Python is fun :red_heart:\", variant=\"emoji_type\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbc85ab-b3df-443e-9c37-57c68aca52b4",
   "metadata": {},
   "source": [
    "#### Extracting emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bdb9e2-d5a4-44e3-9094-ea01c83d833a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# extracting emoji\n",
    "emoji.emoji_list('Python is üëç')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4379c4a4-e504-4904-937f-49ef0163c7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"I love Python! üòçüêç The weather is great today! üòä #happy #sunny üåû\"\n",
    "emoji.emoji_list(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c90384-0fcd-4c67-b2a0-a55d238a9b70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# extract distinct emojis\n",
    "emoji.distinct_emoji_list('Some emoji: üåç, üòÇ, üòÉ, üòÇ, üåç, üå¶Ô∏è')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6135da26-bb6f-44cb-bd31-0b22d67efa8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# count the number of emojis\n",
    "emoji.emoji_count('Some emoji: üåç, üòÇ, üòÉ, üòÇ, üåç, üå¶Ô∏è')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e200f79-b5b9-48c4-afd9-66bdeb2d1aeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "emoji.emoji_count('Some emoji: üåç, üòÇ, üòÉ, üòÇ, üåç, üå¶Ô∏è', unique=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fa4d90-4ce8-4b45-8277-76939b0eb719",
   "metadata": {},
   "source": [
    "## 3. Sentiment Analysis\n",
    "\n",
    "Sentiment analysis is the process of determining the sentiment or emotion expressed in a piece of text. We will use the TextBlob library to perform a simple sentiment analysis on the tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d49c7d2-cdf4-4d11-9236-6d8205e95f8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5985138-8fc7-458e-a386-53400a3f66aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "def get_sentiment(text):\n",
    "    analysis = TextBlob(text)\n",
    "    if analysis.sentiment.polarity > 0:\n",
    "        return 'positive'\n",
    "    elif analysis.sentiment.polarity == 0:\n",
    "        return 'neutral'\n",
    "    else:\n",
    "        return 'negative'\n",
    "\n",
    "sentiment = get_sentiment(text)\n",
    "sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f60feb-8222-4499-b45a-6584ed6641b4",
   "metadata": {},
   "source": [
    "## 4. Regular Expressions for Advanced Text Cleaning\n",
    "\n",
    "Regular expressions are a powerful tool for advanced text cleaning. We will use them to remove URLs, mentions, and special characters from the tweet text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204a273b-2682-4e09-82e0-7757759f5a50",
   "metadata": {},
   "source": [
    "### 4.1 Removing URLs\n",
    "\n",
    "To remove URLs from the text, we can use the following regular expression pattern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0811ef-a502-43a6-8060-038de5e2943e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_urls(text):\n",
    "    url_pattern = re.compile(r'https?://\\S+|www.\\S+')\n",
    "    return url_pattern.sub('', text)\n",
    "\n",
    "text = \"Check out this amazing article: https://example.com/article #learning\"\n",
    "cleaned_text = remove_urls(text)\n",
    "cleaned_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742e61bf-4cee-43e7-a172-750c100a3a79",
   "metadata": {},
   "source": [
    "### 4.2 Removing User Mentions\n",
    "\n",
    "To remove user mentions from the text, we can use the following regular expression pattern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10db114-f6a2-4dbd-9af9-fde3a913ea01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_mentions(text):\n",
    "    mention_pattern = re.compile(r'@\\w+')\n",
    "    return mention_pattern.sub('', text)\n",
    "\n",
    "text = \"Thanks for the great article, @johndoe! #appreciation\"\n",
    "cleaned_text = remove_mentions(text)\n",
    "cleaned_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77b8126-fc8b-4948-aa33-239270070791",
   "metadata": {},
   "source": [
    "### 4.3 Removing Hashtags\n",
    "\n",
    "To remove hashtags from the text, we can use the following regular expression pattern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814b1f77-13d8-410c-a262-d77cb5d33426",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_hashtags(text):\n",
    "    hashtag_pattern = re.compile(r'#\\w+')\n",
    "    return hashtag_pattern.sub('', text).strip()\n",
    "\n",
    "text = \"I love Python! üòçüêç #python #programming\"\n",
    "cleaned_text = remove_hashtags(text)\n",
    "cleaned_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d27a3c-206c-42a7-906e-03d89dada638",
   "metadata": {},
   "source": [
    "### 4.4 All-in-One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144333ac-2283-4329-a086-e75dd26d481d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)  # remove URLs\n",
    "    text = re.sub(r'@\\w+', '', text)  # remove mentions\n",
    "    text = re.sub(r'\\W', ' ', text)  # remove special characters\n",
    "    text = re.sub(r'\\s+', ' ', text)  # remove extra spaces\n",
    "    return text.strip()\n",
    "\n",
    "text = \"Check out this amazing article: https://example.com/article #learning, Thanks for the great article, @johndoe! #appreciation, I love Python! üòçüêç #python #programming\"\n",
    "cleaned_text = clean_text(text)\n",
    "cleaned_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbe163d-16ba-4d58-a171-d86f1cc5a56e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d343a3-f43e-4392-853a-5013b5febf9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba039dfe-ac2c-4439-8f4f-bff6b78cc4f3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296c7462-ab8d-4e36-af59-7b43521a402f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8234533b-7211-4886-ad51-4bba3c3fb4c9",
   "metadata": {},
   "source": [
    "### 6.1 Finding Collocations\n",
    "\n",
    "To find collocations, we can use the `nltk` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933e90a2-a365-468d-a1d4-81a1c0079f26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.collocations import BigramAssocMeasures, BigramCollocationFinder\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "def find_collocations(text, num_collocations=10):\n",
    "    \"\"\"\n",
    "    This function takes a text input and finds the top collocations (bigrams) based on their\n",
    "    pointwise mutual information (PMI) scores.\n",
    "\n",
    "    :param text: str, input text to analyze for collocations\n",
    "    :param num_collocations: int, optional, the number of top bigrams to return based on their PMI scores\n",
    "                             (default is 10)\n",
    "    :return: list of tuples, the top num_collocations bigrams with the highest PMI scores\n",
    "    \"\"\"\n",
    "    # Tokenize the input text\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    # Create a BigramAssocMeasures object to compute the PMI scores\n",
    "    bigram_measures = BigramAssocMeasures()\n",
    "    # Create a BigramCollocationFinder object from the tokens\n",
    "    finder = BigramCollocationFinder.from_words(tokens)\n",
    "    # Apply a frequency filter to keep only bigrams that appear at least twice\n",
    "    finder.apply_freq_filter(2)\n",
    "    # Apply a word filter to exclude bigrams containing stopwords or punctuations\n",
    "    finder.apply_word_filter(lambda w: w.lower() in stopwords.words('english') or w in string.punctuation)\n",
    "    # Return the top num_collocations bigrams with the highest PMI scores\n",
    "    return finder.nbest(bigram_measures.pmi, num_collocations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4a9b31-e3e5-4722-930d-c2a18f214961",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space_text = '''\n",
    "Space exploration has been a topic of fascination for scientists, researchers, and the general public for decades. One of the most intriguing aspects of space exploration is the possibility of colonizing other planets, such as Mars. In recent years, multiple space agencies and private companies have set their sights on sending humans to Mars and establishing a permanent settlement on the red planet.\n",
    "\n",
    "Mars has long been considered a potential candidate for human colonization due to its similarities to Earth in terms of climate, geology, and the presence of water ice. However, there are numerous challenges that must be overcome before humans can safely set foot on the Martian surface. These challenges include developing advanced propulsion systems, creating sustainable habitats, and ensuring the health and safety of astronauts during the long journey to Mars.\n",
    "\n",
    "Several ambitious Mars missions are currently being planned by various organizations, including NASA, the European Space Agency (ESA), and private companies like SpaceX. These missions aim to further our understanding of Mars' geology, climate, and potential habitability, as well as to test the technologies needed for future human exploration.\n",
    "\n",
    "One of the most notable Mars missions is NASA's Mars 2020 mission, which successfully landed the Perseverance rover on the Martian surface in February 2021. Perseverance has been exploring the Jezero Crater, searching for signs of ancient life and collecting samples to be returned to Earth by a future mission.\n",
    "\n",
    "Meanwhile, SpaceX founder Elon Musk has announced ambitious plans to send humans to Mars as early as 2024, with the ultimate goal of establishing a self-sustaining colony on the planet. SpaceX's Starship, a reusable spacecraft currently under development, is designed to transport large numbers of people and cargo to Mars and other destinations in the solar system.\n",
    "\n",
    "As the race to Mars continues, the world eagerly awaits the next major milestone in human space exploration. The potential discovery of past or present life on Mars, as well as the establishment of a permanent human presence on the red planet, would undoubtedly have profound implications for our understanding of the universe and our place in it.\n",
    "'''\n",
    "\n",
    "collocations = find_collocations(space_text)\n",
    "print(collocations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b997a1-6602-4e42-83a7-e7f6ab1a9481",
   "metadata": {},
   "source": [
    "## Exercise: Exploratory Data Analysis on Social Media Data\n",
    "\n",
    "Now that we have covered several intermediate text data analysis techniques, let's apply them to a real-life social media dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2376bdff-f1d1-455a-992c-b49826876f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary libraries\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bd50b6-8ff9-419b-9569-ef5a0a3eb237",
   "metadata": {},
   "source": [
    "Load the dataset and take a look at the first few rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6721dbac-fda7-4d72-99a5-d3276caef8fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Tweets.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcf04d3-57ba-4e71-8396-778dd6cec416",
   "metadata": {},
   "source": [
    "### 1. Social Media Data Characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b5dc8d-26fe-4210-8b92-553003af74ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde2168d-2994-414b-adaf-a6d8f65290f1",
   "metadata": {},
   "source": [
    "### 2. Emoji and Emoticon Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b4124c-26ed-4e9f-a504-bb49ad7587bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_emojis(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.findall(text)\n",
    "\n",
    "df['emojis'] = df['text'].apply(extract_emojis)\n",
    "df['emojis'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3f9fa1-3da7-44dd-8199-0dd6d9574c5e",
   "metadata": {},
   "source": [
    "### 3. Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3beb3d6f-4808-4cee-a0d0-2b9f747bb0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()\n",
    "df['sentiment_scores'] = df['text'].apply(lambda x: sia.polarity_scores(x))\n",
    "df['sentiment_scores'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbf02a6-791c-4a3b-8cec-6a8e6dc40f67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # explode the column 'sentiment_scores' to multiple columns\n",
    "# df['sentiment_scores'].apply(pd.Series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec58f88e-d0f2-4e99-aee6-481ff372418a",
   "metadata": {},
   "source": [
    "### 4. Regular Expressions for Advanced Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b661bb1c-2ce6-4572-b1a3-6a77aaccc4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r\"@\\w+\", \"\", text)  # Remove mentions\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text, flags=re.MULTILINE)  # Remove URLs\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    return text\n",
    "\n",
    "# df['cleaned_text'] = df['text'].apply(clean_text)\n",
    "# df['cleaned_text'].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
