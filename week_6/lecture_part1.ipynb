{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a292ab0-29b6-4fbc-a2bd-56a0303b0731",
   "metadata": {},
   "source": [
    "# Intermediate Text Data Analysis Techniques and Introduction to Social Media Data\n",
    "\n",
    "Table of Contents\n",
    "\n",
    "1. Social Media Data Characteristics\n",
    "2. Emoji and Emoticon Analysis\n",
    "3. Sentiment Analysis\n",
    "4. Regular Expressions for Advanced Text Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a9c578-1f04-43ec-9022-a9668c04eba3",
   "metadata": {},
   "source": [
    "## 1. Social Media Data Characteristics\n",
    "\n",
    "Social media data has some unique characteristics that make it different from other types of text data:\n",
    "\n",
    "1. Shorter texts (e.g., tweets, comments)\n",
    "2. Informal language and slang\n",
    "3. Emojis and emoticons\n",
    "4. URLs, mentions, and hashtags\n",
    "\n",
    "Understanding these characteristics is essential for effectively processing and analyzing social media data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b746f0c-5c87-48ca-bdd0-311c59c417e8",
   "metadata": {},
   "source": [
    "## 2. Emoji and Emoticon Analysis\n",
    "\n",
    "Emojis and emoticons are widely used in social media data to express emotions. Analyzing them can help us understand the sentiment of the text. We will use the emoji library to extract and analyze emojis in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5997e56-d911-4e6e-a7a8-c2b7a6579858",
   "metadata": {},
   "source": [
    "### 2.1 Extracting Emojis and Emoticons\n",
    "\n",
    "Python package: [emoji](https://carpedm20.github.io/emoji/docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab9ef5f-919c-4339-a3a7-f68142563c90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788fac9f-4b1f-4ee5-912b-c0939b3e682d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import emoji\n",
    "\n",
    "print(emoji.emojize('Python is :thumbs_up:'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ab99f5-931f-470b-98bb-a2fd85148443",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(emoji.emojize(\"Python is fun :red_heart:\", variant=\"text_type\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c563eaf-e005-411f-924c-be9244e0aae1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(emoji.emojize(\"Python is fun :red_heart:\", variant=\"emoji_type\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbc85ab-b3df-443e-9c37-57c68aca52b4",
   "metadata": {},
   "source": [
    "#### Extracting emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bdb9e2-d5a4-44e3-9094-ea01c83d833a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# extracting emoji\n",
    "emoji.emoji_list('Python is üëç')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4379c4a4-e504-4904-937f-49ef0163c7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"I love Python! üòçüêç The weather is great today! üòä #happy #sunny üåû\"\n",
    "emoji.emoji_list(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c90384-0fcd-4c67-b2a0-a55d238a9b70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# extract distinct emojis\n",
    "emoji.distinct_emoji_list('Some emoji: üåç, üòÇ, üòÉ, üòÇ, üåç, üå¶Ô∏è')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6135da26-bb6f-44cb-bd31-0b22d67efa8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# count the number of emojis\n",
    "emoji.emoji_count('Some emoji: üåç, üòÇ, üòÉ, üòÇ, üåç, üå¶Ô∏è')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e200f79-b5b9-48c4-afd9-66bdeb2d1aeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "emoji.emoji_count('Some emoji: üåç, üòÇ, üòÉ, üòÇ, üåç, üå¶Ô∏è', unique=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fa4d90-4ce8-4b45-8277-76939b0eb719",
   "metadata": {},
   "source": [
    "## 3. Sentiment Analysis\n",
    "\n",
    "Sentiment analysis is the process of determining the sentiment or emotion expressed in a piece of text. We will use the TextBlob library to perform a simple sentiment analysis on the tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d49c7d2-cdf4-4d11-9236-6d8205e95f8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5985138-8fc7-458e-a386-53400a3f66aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "def get_sentiment(text):\n",
    "    analysis = TextBlob(text)\n",
    "    if analysis.sentiment.polarity > 0:\n",
    "        return 'positive'\n",
    "    elif analysis.sentiment.polarity == 0:\n",
    "        return 'neutral'\n",
    "    else:\n",
    "        return 'negative'\n",
    "\n",
    "sentiment = get_sentiment(text)\n",
    "sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f60feb-8222-4499-b45a-6584ed6641b4",
   "metadata": {},
   "source": [
    "## 4. Regular Expressions for Advanced Text Cleaning\n",
    "\n",
    "Regular expressions are a powerful tool for advanced text cleaning. We will use them to remove URLs, mentions, and special characters from the tweet text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204a273b-2682-4e09-82e0-7757759f5a50",
   "metadata": {},
   "source": [
    "### 4.1 Removing URLs\n",
    "\n",
    "To remove URLs from the text, we can use the following regular expression pattern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0811ef-a502-43a6-8060-038de5e2943e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_urls(text):\n",
    "    url_pattern = re.compile(r'https?://\\S+|www.\\S+')\n",
    "    return url_pattern.sub('', text)\n",
    "\n",
    "text = \"Check out this amazing article: https://example.com/article #learning\"\n",
    "cleaned_text = remove_urls(text)\n",
    "cleaned_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742e61bf-4cee-43e7-a172-750c100a3a79",
   "metadata": {},
   "source": [
    "### 4.2 Removing User Mentions\n",
    "\n",
    "To remove user mentions from the text, we can use the following regular expression pattern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10db114-f6a2-4dbd-9af9-fde3a913ea01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_mentions(text):\n",
    "    mention_pattern = re.compile(r'@\\w+')\n",
    "    return mention_pattern.sub('', text)\n",
    "\n",
    "text = \"Thanks for the great article, @johndoe! #appreciation\"\n",
    "cleaned_text = remove_mentions(text)\n",
    "cleaned_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77b8126-fc8b-4948-aa33-239270070791",
   "metadata": {},
   "source": [
    "### 4.3 Removing Hashtags\n",
    "\n",
    "To remove hashtags from the text, we can use the following regular expression pattern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814b1f77-13d8-410c-a262-d77cb5d33426",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_hashtags(text):\n",
    "    hashtag_pattern = re.compile(r'#\\w+')\n",
    "    return hashtag_pattern.sub('', text).strip()\n",
    "\n",
    "text = \"I love Python! üòçüêç #python #programming\"\n",
    "cleaned_text = remove_hashtags(text)\n",
    "cleaned_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d27a3c-206c-42a7-906e-03d89dada638",
   "metadata": {},
   "source": [
    "### 4.4 All-in-One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144333ac-2283-4329-a086-e75dd26d481d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)  # remove URLs\n",
    "    text = re.sub(r'@\\w+', '', text)  # remove mentions\n",
    "    text = re.sub(r'\\W', ' ', text)  # remove special characters\n",
    "    text = re.sub(r'\\s+', ' ', text)  # remove extra spaces\n",
    "    return text.strip()\n",
    "\n",
    "text = \"Check out this amazing article: https://example.com/article #learning, Thanks for the great article, @johndoe! #appreciation, I love Python! üòçüêç #python #programming\"\n",
    "cleaned_text = clean_text(text)\n",
    "cleaned_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b997a1-6602-4e42-83a7-e7f6ab1a9481",
   "metadata": {},
   "source": [
    "## Exercise: Exploratory Data Analysis on Social Media Data\n",
    "\n",
    "Now that we have covered several intermediate text data analysis techniques, let's apply them to a real-life social media dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2376bdff-f1d1-455a-992c-b49826876f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary libraries\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bd50b6-8ff9-419b-9569-ef5a0a3eb237",
   "metadata": {},
   "source": [
    "Load the dataset and take a look at the first few rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6721dbac-fda7-4d72-99a5-d3276caef8fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Tweets.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcf04d3-57ba-4e71-8396-778dd6cec416",
   "metadata": {},
   "source": [
    "### 1. Social Media Data Characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b5dc8d-26fe-4210-8b92-553003af74ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde2168d-2994-414b-adaf-a6d8f65290f1",
   "metadata": {},
   "source": [
    "### 2. Emoji and Emoticon Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b4124c-26ed-4e9f-a504-bb49ad7587bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_emojis(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.findall(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bf7148-fdd0-4221-9b6e-1c3ff01d3bc0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['emojis'] = df['text'].apply(extract_emojis)\n",
    "df['emojis'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3f9fa1-3da7-44dd-8199-0dd6d9574c5e",
   "metadata": {},
   "source": [
    "### 3. Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3beb3d6f-4808-4cee-a0d0-2b9f747bb0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()\n",
    "df['sentiment_scores'] = df['text'].apply(lambda x: sia.polarity_scores(x))\n",
    "df['sentiment_scores'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbf02a6-791c-4a3b-8cec-6a8e6dc40f67",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # explode the column 'sentiment_scores' to multiple columns\n",
    "# df['sentiment_scores'].apply(pd.Series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec58f88e-d0f2-4e99-aee6-481ff372418a",
   "metadata": {},
   "source": [
    "### 4. Regular Expressions for Advanced Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b661bb1c-2ce6-4572-b1a3-6a77aaccc4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r\"@\\w+\", \"\", text)  # Remove mentions\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text, flags=re.MULTILINE)  # Remove URLs\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82927364-f5d8-4e7d-bb6c-ba944c40fcbf",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df['cleaned_text'] = df['text'].apply(clean_text)\n",
    "# df['cleaned_text'].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
