{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dced906b-b3b3-4da5-89eb-2fe459b6b696",
   "metadata": {},
   "source": [
    "# Introduction to Topic Modeling and Implementing Topic Modeling Techniques\n",
    "\n",
    "Topic Modeling is a type of statistical modeling used to uncover hidden structure in a collection of texts. In simpler terms, it is a way to find the main topics that emerge from a large set of documents. Topic modeling is part of a larger group of algorithms known as 'unsupervised learning'. 'Unsupervised' because we don't provide the algorithm with predefined labels, it finds structure on its own, and 'learning' because it gets better and better as it processes more data.\n",
    "\n",
    "In communication research, Topic Modeling is often used to identify themes or discourses in a large collection of documents, such as newspaper articles or social media posts. For example, a researcher might be interested in understanding the primary narratives around climate change on Twitter, or the main themes in news coverage of an election. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1e1dc6-89ee-410b-8bd4-17f1689b819e",
   "metadata": {},
   "source": [
    "## LDA - Latent Dirichlet Allocation\n",
    "\n",
    "There are several algorithms for Topic Modeling such as Latent Semantic Indexing (LSI), Probabilistic Latent Semantic Analysis (pLSA), and Latent Dirichlet Allocation (LDA). In this lesson, we'll focus on Latent Dirichlet Allocation (LDA), which is one of the most popular techniques for Topic Modeling.\n",
    "\n",
    "LDA assumes that every document is a mixture of topics and each topic is a mixture of words. This assumption helps us find topics which are nothing but a bunch of words ordered with a probability that defines how important a word is, for that particular topic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfd266a-64d6-4cde-8777-91132d00b5fe",
   "metadata": {},
   "source": [
    "# Examples of Communication Research Questions That Can Be Answered by Topic Modeling\n",
    "\n",
    "1. **News Media:** What are the primary topics covered by a news outlet during a certain period? Does the focus of topics change over time?\n",
    "\n",
    "2. **Social Media:** What are the main themes in public discourse about a particular issue on social media platforms like Twitter, Facebook, or Reddit?\n",
    "\n",
    "3. **Political Speeches:** What topics do politicians focus on in their speeches? Does the focus change based on the political context?\n",
    "\n",
    "4. **Public Opinions:** What are the primary concerns of the public about a particular issue, as reflected in letters to the editor, public comments on news websites, or online discussion forums?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d83f452-645f-4414-92ec-ae385689e6be",
   "metadata": {},
   "source": [
    "# Types of Data That Can Be Analyzed by Topic Modeling\n",
    "\n",
    "Virtually any type of text data can be analyzed with topic modeling. This includes, but is not limited to:\n",
    "\n",
    "1. **News Articles:** Topic modeling can help discover the main themes in a large collection of news articles.\n",
    "\n",
    "2. **Social Media Posts:** Topic modeling can be used to understand public discourse on social media platforms.\n",
    "\n",
    "3. **Political Speeches:** Analyze the content of speeches to understand the primary themes.\n",
    "\n",
    "4. **Research Papers:** Discover the main research themes in a set of academic papers.\n",
    "\n",
    "The applications of topic modeling are vast and varied. In your final project for this course, you might consider how topic modeling could help answer your research questions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e0406d-2ae7-40fc-800a-3d79bbe7c5f6",
   "metadata": {},
   "source": [
    "## Load and Preprocess the Data\n",
    "\n",
    "Suppose we have a dataset of tweets related to mental health. We'll load this data and then preprocess it by removing stop words and converting all text to lowercase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1729a3-91ce-4b9d-9a79-6a6a38521bb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6363aa2b-f4b9-43b2-92ba-4ed6fc5ac6aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import the necessary packages\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "# Make sure you have the stop words package downloaded\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae2c74b-5aa1-447b-9c90-92731472d680",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('tweets.csv')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    # Remove RT (retweet sign)\n",
    "    text = re.sub(r'rt[\\s]+', '', text)\n",
    "    # Remove mentions\n",
    "    text = re.sub(r'@\\S+', '', text)\n",
    "    # Remove all non-alphabetic characters\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    # Remove single characters\n",
    "    text = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', text)\n",
    "    # Remove leading and trailing whitespaces\n",
    "    text = text.strip()\n",
    "    # Remove stopwords and do stemming\n",
    "    # text = \" \".join([stemmer.stem(i) for i in text.split() if i not in stop_words])\n",
    "    return text\n",
    "\n",
    "df['text_cleaned'] = df['post_text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcd16c6-3dee-4d08-bdad-52d06ad3ef97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['text_cleaned']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c224d2f-5acb-403d-acb4-a57bc0ebbffb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We will only use the 'text_cleaned' column for our analysis\n",
    "documents = df['text_cleaned']\n",
    "\n",
    "# Initialize CountVectorizer\n",
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "# Fit and transform the processed titles\n",
    "count_data = count_vectorizer.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68154fd-2001-471b-890e-300b5c776d36",
   "metadata": {},
   "source": [
    "## Construct the Topic Model\n",
    "\n",
    "Now we're ready to construct a topic model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539658ee-5355-42e9-86e6-0709232fede3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tweak the two parameters below (use int values below 15)\n",
    "number_topics = 5\n",
    "number_words = 10\n",
    "\n",
    "# Create and fit the LDA model\n",
    "lda = LDA(n_components=number_topics, n_jobs=-1)\n",
    "lda.fit(count_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0599324b-0f91-4b99-910e-ab5fc506799f",
   "metadata": {},
   "source": [
    "## View the Topics\n",
    "\n",
    "Lastly, let's view the topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e39583-ca4d-45bb-96fd-6640140ad1e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_topics(model, count_vectorizer, n_top_words):\n",
    "    words = count_vectorizer.get_feature_names_out()\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"\\nTopic #%d:\" % topic_idx)\n",
    "        print(\" \".join([words[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "\n",
    "print_topics(lda, count_vectorizer, number_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915b118b-b902-45f4-aab7-905dc6e5f698",
   "metadata": {},
   "source": [
    "This should display a list of topics, each represented as a list of words. Understanding these topics can be very useful for communication research. For instance, it can help identify how public discourse around a given topic changes over time, or detect different narratives in public discourse.\n",
    "\n",
    "Remember, the choice of the number of topics (`number_topics`) and the number of top words (`number_words`) can significantly influence the results. So, feel free to experiment with these values to see how the topics change."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b0e474-4bfd-45fb-be70-039c69b79a82",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5be67c9-ab81-484f-b77e-2552c350157e",
   "metadata": {},
   "source": [
    "### 1. Topic distribution across documents:\n",
    "\n",
    "Preparing the LDA model's output (topic distribution for each document) to be visualized using t-SNE, which is a technique for reducing the dimensionality of data (specifically, it's used for visualizing high-dimensional data in 2 or 3 dimensions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be476fe-5c28-4ea4-b04a-b70943f64fdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Get topic weights\n",
    "topic_weights = []\n",
    "for i, row_list in enumerate(lda.transform(count_data)):\n",
    "    topic_weights.append([w for i, w in enumerate(row_list)])\n",
    "\n",
    "# Array of topic weights    \n",
    "arr = pd.DataFrame(topic_weights).fillna(0).values\n",
    "\n",
    "# Keep the well separated points (optional)\n",
    "arr = arr[np.amax(arr, axis=1) > 0.35]\n",
    "\n",
    "# Dominant topic number in each doc\n",
    "topic_num = np.argmax(arr, axis=1)\n",
    "\n",
    "# tSNE Dimension Reduction\n",
    "tsne_model = TSNE(n_components=2, verbose=1, random_state=0, angle=.99, init='pca')\n",
    "tsne_lda = tsne_model.fit_transform(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932ca085-e8f8-4c4e-8653-505f49775a55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install bokeh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f94cd02-4c61-4b3f-b49e-563abc8db39c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bokeh.io import output_notebook\n",
    "from bokeh.plotting import figure, show\n",
    "# Plot the Topic Clusters using Bokeh\n",
    "output_notebook()\n",
    "mycolors = np.array([color for name, color in mcolors.TABLEAU_COLORS.items()])\n",
    "plot = figure(title=\"t-SNE Clustering of {} LDA Topics\".format(number_topics), \n",
    "              width=900, height=700)\n",
    "plot.scatter(x=tsne_lda[:,0], y=tsne_lda[:,1], color=mycolors[topic_num])\n",
    "show(plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4540c3-4656-4a00-aa89-2c0df3412078",
   "metadata": {},
   "source": [
    "### 2. Inter-topic distance visualization: [Link](https://nbviewer.org/github/bmabey/hacker_news_topic_modelling/blob/master/HN%20Topic%20Model%20Talk.ipynb#topic=51&lambda=1&term=)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
